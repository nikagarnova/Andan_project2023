{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5bc102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16000 candidates, totalling 48000 fits\n",
      "максимизация roc-auc\n",
      "accuracy =  0.6104046242774567 ; roc_auc =  0.6070301973951538 ; precision =  0.5700280112044818 ; recall =  0.931350114416476\n"
     ]
    }
   ],
   "source": [
    "# №3 оценка модели. Предсказание, относится фильм к жанру Drama или нет\n",
    "# только 'release_year', 'imdb_rate', 'metascore_rate', 'votes', 'duration'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections\n",
    "np.random.seed(123)\n",
    "\n",
    "# Отключение некоторых лишних предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "        \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "df = pd.read_csv('result_films.csv')\n",
    "\n",
    "# Создаем список уникальных жанров\n",
    "genres = set()\n",
    "for genre_list in df['genre']:\n",
    "    genres.update(genre_list.split(', '))\n",
    "\n",
    "\n",
    "# Создаем новые столбцы для каждого жанра и заполняем их нулями\n",
    "for genre in genres:\n",
    "    df[genre] = 0\n",
    "\n",
    "# Обновляем значения столбцов жанров\n",
    "for index, row in df.iterrows():\n",
    "    genre_list = row['genre'].split(', ')\n",
    "    for genre in genre_list:\n",
    "        df.at[index, genre] = 1\n",
    "\n",
    "# Извлекаем год выпуска фильма и сохраняем его в отдельный столбец \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# Удаляем скобки и \"(I)\" из столбца \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.replace(r'\\(I\\)', '')\n",
    "\n",
    "# Преобразуем столбец \"release_year\" в числовой формат\n",
    "df['release_year'] = df['release_year'].astype(int)\n",
    "\n",
    "\n",
    "# Удаление столбца \"genre\"\n",
    "df_1 = df.drop({'name', 'global_rate','description', 'genre', 'Film-Noir', 'Family',\n",
    "               'Sci-Fi', 'Adventure', 'Western', 'Crime', 'Horror', 'Comedy',\n",
    "               'Romance', 'War', 'Musical', 'Mystery', 'Animation', 'Action',\n",
    "               'Biography', 'History', 'Sport', 'Music', 'Fantasy', 'Thriller'}, axis=1)\n",
    "\n",
    "\n",
    "# Удаление слова \"min\" и преобразование значения в числовой тип данных\n",
    "df_1[\"duration\"] = df_1[\"duration\"].str.replace(\" min\", \"\")\n",
    "\n",
    "# Замена пропущенных значений на нули\n",
    "df_1[\"duration\"].fillna(0, inplace=True)\n",
    "df_1[\"duration\"] = df_1[\"duration\"].astype(int)\n",
    "\n",
    "# Нормализация значений в столбцах\n",
    "df_1[\"release_year\"] = pd.to_numeric(df[\"release_year\"], errors='coerce').astype(float)\n",
    "df_1[\"imdb_rate\"] = df_1[\"imdb_rate\"].str.replace(',', '.').astype(float)\n",
    "df_1[\"metascore_rate\"] = pd.to_numeric(df[\"metascore_rate\"], errors='coerce').astype(float)\n",
    "df_1[\"votes\"] = pd.to_numeric(df[\"votes\"], errors='coerce').astype(float)\n",
    "\n",
    "cols_to_normalize = [\"release_year\",\"imdb_rate\", \"metascore_rate\", \"votes\", \"duration\"]\n",
    "df_1[cols_to_normalize] = df_1[cols_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "features = df_1.drop(['Drama'], axis=1)  # Исключаем столбец 'Comedy'\n",
    "target = df_1['Drama']\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_data = X_train.select_dtypes([np.number])\n",
    "\n",
    "numeric_data_mean = numeric_data.mean() \n",
    "numeric_features = numeric_data.columns\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "#нормирование данных\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1,scoring=\"roc_auc\" )\n",
    "\n",
    "best_clf = clf.fit(X_train_scaled,y_train)\n",
    "best_clf.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('максимизация roc-auc')\n",
    "print('accuracy = ', accuracy, '; roc_auc = ',  roc_auc,'; precision = ', precision,'; recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1d301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16000 candidates, totalling 48000 fits\n",
      "максимизация roc-auc\n",
      "accuracy =  0.6011560693641619 ; roc_auc =  0.6008121431168332 ; precision =  0.5995670995670995 ; recall =  0.6338672768878718\n"
     ]
    }
   ],
   "source": [
    "# №3 оценка модели. Предсказание, относится фильм к жанру Drama или нет\n",
    "# столбцы слов из описания и тематические  (любовь, война, приключения, убийтсва),\n",
    "#БЕЗ данных о рейтинге, длительности и количестве голосов\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections\n",
    "np.random.seed(123)\n",
    "\n",
    "# Отключение некоторых лишних предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "        \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "df = pd.read_csv('result_films.csv')\n",
    "\n",
    "# Создаем список уникальных жанров\n",
    "genres = set()\n",
    "for genre_list in df['genre']:\n",
    "    genres.update(genre_list.split(', '))\n",
    "\n",
    "\n",
    "# Считывание списка из файла в переменную\n",
    "with open('unmeaning_words.txt', 'r') as file:\n",
    "    unmeaning_words = file.read().splitlines()\n",
    "\n",
    "with open('love_words.txt', 'r') as file:\n",
    "    love_word_list = file.read().splitlines()\n",
    "\n",
    "with open('death_words.txt', 'r') as file:\n",
    "    death_word_list = file.read().splitlines()\n",
    "    \n",
    "with open('war_words.txt', 'r') as file:\n",
    "    war_word_list = file.read().splitlines()\n",
    "    \n",
    "with open('journey_words.txt', 'r') as file:\n",
    "    journey_word_list = file.read().splitlines()   \n",
    "\n",
    "# Создаем новые столбцы для каждого жанра и заполняем их нулями\n",
    "for genre in genres:\n",
    "    df[genre] = 0\n",
    "\n",
    "# Обновляем значения столбцов жанров\n",
    "for index, row in df.iterrows():\n",
    "    genre_list = row['genre'].split(', ')\n",
    "    for genre in genre_list:\n",
    "        df.at[index, genre] = 1\n",
    "        \n",
    "# Список с результатами\n",
    "top_words_list = []\n",
    "\n",
    "for genre in genres:\n",
    "    # Фильтрация фильмов по жанру и выбор столбца 'description'\n",
    "    films = df[df[genre] == 1]['description']\n",
    "\n",
    "    # Сбор всех описаний в один текст\n",
    "    descriptions = ' '.join(films)\n",
    "\n",
    "    # Разделение текста на отдельные слова\n",
    "    words = descriptions.lower().split()\n",
    "\n",
    "    # Подсчет количества слов, за исключением слов из списка unmeaning_words\n",
    "    word_counts = collections.Counter(word for word in words if word not in unmeaning_words)\n",
    "\n",
    "    # Получение 20 самых часто встречающихся слов\n",
    "    top_words = [word for word, count in word_counts.most_common(20)]\n",
    "\n",
    "    # Сохранение результатов в список\n",
    "    top_words_list.append((genre, top_words))\n",
    "\n",
    "\n",
    "# Перебор элементов списка top_words_list\n",
    "for genre, top_words in top_words_list:\n",
    "    # Создание имени столбца\n",
    "    column_name = f\"word_from_{genre}\"\n",
    "\n",
    "    # Создание нового столбца с начальным значением 0\n",
    "    df[column_name] = 0\n",
    "\n",
    "    # Перебор описаний фильмов\n",
    "    for index, row in df.iterrows():\n",
    "        description = row['description'].lower()  # Преобразуем текст описания в нижний регистр\n",
    "        \n",
    "        # Проверка наличия слов из списка top_words в описании\n",
    "        if any(word in description for word in top_words):\n",
    "            # Установка значения 1, если хотя бы одно слово найдено\n",
    "            df.loc[index, column_name] = 1\n",
    "\n",
    "df['love_presence'] = 0\n",
    "df['war_presence'] = 0\n",
    "df['journey_presence'] = 0\n",
    "df['death_presence'] = 0\n",
    "\n",
    "# Проходим по каждой строке таблицы\n",
    "for index, row in df.iterrows():\n",
    "    description = row['description'].lower()  # Преобразуем текст описания в нижний регистр\n",
    "        \n",
    "    # Проверяем наличие слов из списка love_word_list\n",
    "    if any(word in description for word in love_word_list):\n",
    "        df.at[index, 'love_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка war_word_list\n",
    "    if any(word in description for word in war_word_list):\n",
    "        df.at[index, 'war_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка journey_word_list\n",
    "    if any(word in description for word in journey_word_list):\n",
    "        df.at[index, 'journey_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка death_word_list\n",
    "    if any(word in description for word in death_word_list):\n",
    "        df.at[index, 'death_presence'] = 1\n",
    "        \n",
    "# Извлекаем год выпуска фильма и сохраняем его в отдельный столбец \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# Удаляем скобки и \"(I)\" из столбца \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.replace(r'\\(I\\)', '')\n",
    "\n",
    "# Преобразуем столбец \"release_year\" в числовой формат\n",
    "df['release_year'] = df['release_year'].astype(int)\n",
    "\n",
    "\n",
    "# Удаление столбца \"genre\"\n",
    "df_1 = df.drop({'name', 'global_rate', 'release_year', 'imdb_rate', 'metascore_rate',\n",
    "               'description', 'votes', 'duration', 'genre', 'Film-Noir', 'Family',\n",
    "               'Sci-Fi', 'Adventure', 'Western', 'Crime', 'Horror', 'Comedy',\n",
    "               'Romance', 'War', 'Musical', 'Mystery', 'Animation', 'Action',\n",
    "               'Biography', 'History', 'Sport', 'Music', 'Fantasy', 'Thriller'}, axis=1)\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "features = df_1.drop(['Drama'], axis=1)  # Исключаем столбец 'Comedy'\n",
    "target = df_1['Drama']\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_data = X_train.select_dtypes([np.number])\n",
    "\n",
    "numeric_data_mean = numeric_data.mean() \n",
    "numeric_features = numeric_data.columns\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "#нормирование данных\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "## подбор Solver'a\n",
    "## идеи с сайта https://www.kaggle.com/code/funxexcel/p2-logistic-regression-hyperparameter-tuning\n",
    "\n",
    "logModel = LogisticRegression()\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-5, 5, 40),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : np.logspace(0, 5, 20)\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1,scoring=\"roc_auc\" )\n",
    "\n",
    "best_clf = clf.fit(X_train_scaled,y_train)\n",
    "best_clf.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('максимизация roc-auc')\n",
    "print('accuracy = ', accuracy, '; roc_auc = ',  roc_auc,'; precision = ', precision,'; recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fdd910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16000 candidates, totalling 48000 fits\n",
      "максимизация roc-auc\n",
      "accuracy =  0.7213872832369942 ; roc_auc =  0.7208157787805556 ; precision =  0.7033195020746889 ; recall =  0.7757437070938215\n"
     ]
    }
   ],
   "source": [
    "# №3 оценка модели. Предсказание, относится фильм к жанру Drama или нет\n",
    "# столбцы слов из описания и тематические  (любовь, война, приключения, убийтсва),\n",
    "# C данными о рейтинге, длительности и количестве голосов\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections\n",
    "np.random.seed(123)\n",
    "\n",
    "# Отключение некоторых лишних предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "        \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "df = pd.read_csv('result_films.csv')\n",
    "\n",
    "# Создаем список уникальных жанров\n",
    "genres = set()\n",
    "for genre_list in df['genre']:\n",
    "    genres.update(genre_list.split(', '))\n",
    "\n",
    "\n",
    "# Считывание списка из файла в переменную\n",
    "with open('unmeaning_words.txt', 'r') as file:\n",
    "    unmeaning_words = file.read().splitlines()\n",
    "\n",
    "with open('love_words.txt', 'r') as file:\n",
    "    love_word_list = file.read().splitlines()\n",
    "\n",
    "with open('death_words.txt', 'r') as file:\n",
    "    death_word_list = file.read().splitlines()\n",
    "    \n",
    "with open('war_words.txt', 'r') as file:\n",
    "    war_word_list = file.read().splitlines()\n",
    "    \n",
    "with open('journey_words.txt', 'r') as file:\n",
    "    journey_word_list = file.read().splitlines()   \n",
    "\n",
    "# Создаем новые столбцы для каждого жанра и заполняем их нулями\n",
    "for genre in genres:\n",
    "    df[genre] = 0\n",
    "\n",
    "# Обновляем значения столбцов жанров\n",
    "for index, row in df.iterrows():\n",
    "    genre_list = row['genre'].split(', ')\n",
    "    for genre in genre_list:\n",
    "        df.at[index, genre] = 1\n",
    "        \n",
    "# Список с результатами\n",
    "top_words_list = []\n",
    "\n",
    "for genre in genres:\n",
    "    # Фильтрация фильмов по жанру и выбор столбца 'description'\n",
    "    films = df[df[genre] == 1]['description']\n",
    "\n",
    "    # Сбор всех описаний в один текст\n",
    "    descriptions = ' '.join(films)\n",
    "\n",
    "    # Разделение текста на отдельные слова\n",
    "    words = descriptions.lower().split()\n",
    "\n",
    "    # Подсчет количества слов, за исключением слов из списка unmeaning_words\n",
    "    word_counts = collections.Counter(word for word in words if word not in unmeaning_words)\n",
    "\n",
    "    # Получение 20 самых часто встречающихся слов\n",
    "    top_words = [word for word, count in word_counts.most_common(20)]\n",
    "\n",
    "    # Сохранение результатов в список\n",
    "    top_words_list.append((genre, top_words))\n",
    "\n",
    "\n",
    "# Перебор элементов списка top_words_list\n",
    "for genre, top_words in top_words_list:\n",
    "    # Создание имени столбца\n",
    "    column_name = f\"word_from_{genre}\"\n",
    "\n",
    "    # Создание нового столбца с начальным значением 0\n",
    "    df[column_name] = 0\n",
    "\n",
    "    # Перебор описаний фильмов\n",
    "    for index, row in df.iterrows():\n",
    "        description = row['description'].lower()  # Преобразуем текст описания в нижний регистр\n",
    "        \n",
    "        # Проверка наличия слов из списка top_words в описании\n",
    "        if any(word in description for word in top_words):\n",
    "            # Установка значения 1, если хотя бы одно слово найдено\n",
    "            df.loc[index, column_name] = 1\n",
    "\n",
    "df['love_presence'] = 0\n",
    "df['war_presence'] = 0\n",
    "df['journey_presence'] = 0\n",
    "df['death_presence'] = 0\n",
    "\n",
    "# Проходим по каждой строке таблицы\n",
    "for index, row in df.iterrows():\n",
    "    description = row['description'].lower()  # Преобразуем текст описания в нижний регистр\n",
    "        \n",
    "    # Проверяем наличие слов из списка love_word_list\n",
    "    if any(word in description for word in love_word_list):\n",
    "        df.at[index, 'love_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка war_word_list\n",
    "    if any(word in description for word in war_word_list):\n",
    "        df.at[index, 'war_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка journey_word_list\n",
    "    if any(word in description for word in journey_word_list):\n",
    "        df.at[index, 'journey_presence'] = 1\n",
    "        \n",
    "    # Проверяем наличие слов из списка death_word_list\n",
    "    if any(word in description for word in death_word_list):\n",
    "        df.at[index, 'death_presence'] = 1\n",
    "            \n",
    "\n",
    "# Извлекаем год выпуска фильма и сохраняем его в отдельный столбец \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# Удаляем скобки и \"(I)\" из столбца \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.replace(r'\\(I\\)', '')\n",
    "\n",
    "# Преобразуем столбец \"release_year\" в числовой формат\n",
    "df['release_year'] = df['release_year'].astype(int)\n",
    "\n",
    "\n",
    "# Удаление столбца \"genre\"\n",
    "df_1 = df.drop({'name', 'global_rate','description', 'genre', 'Film-Noir', 'Family',\n",
    "               'Sci-Fi', 'Adventure', 'Western', 'Crime', 'Horror', 'Comedy',\n",
    "               'Romance', 'War', 'Musical', 'Mystery', 'Animation', 'Action',\n",
    "               'Biography', 'History', 'Sport', 'Music', 'Fantasy', 'Thriller'}, axis=1)\n",
    "\n",
    "\n",
    "# Удаление слова \"min\" и преобразование значения в числовой тип данных\n",
    "df_1[\"duration\"] = df_1[\"duration\"].str.replace(\" min\", \"\")\n",
    "\n",
    "# Замена пропущенных значений на нули\n",
    "df_1[\"duration\"].fillna(0, inplace=True)\n",
    "df_1[\"duration\"] = df_1[\"duration\"].astype(int)\n",
    "\n",
    "# Нормализация значений в столбцах\n",
    "df_1[\"release_year\"] = pd.to_numeric(df[\"release_year\"], errors='coerce').astype(float)\n",
    "df_1[\"imdb_rate\"] = df_1[\"imdb_rate\"].str.replace(',', '.').astype(float)\n",
    "df_1[\"metascore_rate\"] = pd.to_numeric(df[\"metascore_rate\"], errors='coerce').astype(float)\n",
    "df_1[\"votes\"] = pd.to_numeric(df[\"votes\"], errors='coerce').astype(float)\n",
    "\n",
    "cols_to_normalize = [\"release_year\",\"imdb_rate\", \"metascore_rate\", \"votes\", \"duration\"]\n",
    "df_1[cols_to_normalize] = df_1[cols_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "features = df_1.drop(['Drama'], axis=1)  # Исключаем столбец 'Comedy'\n",
    "target = df_1['Drama']\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_data = X_train.select_dtypes([np.number])\n",
    "\n",
    "numeric_data_mean = numeric_data.mean() \n",
    "numeric_features = numeric_data.columns\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "#нормирование данных\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1,scoring=\"roc_auc\" )\n",
    "\n",
    "best_clf = clf.fit(X_train_scaled,y_train)\n",
    "best_clf.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('максимизация roc-auc')\n",
    "print('accuracy = ', accuracy, '; roc_auc = ',  roc_auc,'; precision = ', precision,'; recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15a21a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
