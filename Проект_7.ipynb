{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7882f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      release_year  metascore_rate  Adventure  Family  Fantasy  Animation  \\\n",
      "242           1994              63        0.0     0.0      0.0        0.0   \n",
      "3191          1952              89        0.0     0.0      0.0        0.0   \n",
      "2136          2008              53        0.0     0.0      0.0        0.0   \n",
      "3411          1987              72        0.0     0.0      0.0        0.0   \n",
      "641           2017              45        1.0     0.0      1.0        0.0   \n",
      "...            ...             ...        ...     ...      ...        ...   \n",
      "2515          1982              68        1.0     0.0      0.0        0.0   \n",
      "1487          2013              35        0.0     0.0      0.0        0.0   \n",
      "1543          2014              69        0.0     0.0      0.0        0.0   \n",
      "1798          2020              63        1.0     0.0      0.0        0.0   \n",
      "1126          1993              87        0.0     0.0      0.0        0.0   \n",
      "\n",
      "      Action  Crime  Thriller  Comedy  ...  Quan_4_survive  Quan_4_island  \\\n",
      "242      1.0    0.0       1.0     1.0  ...               0              0   \n",
      "3191     0.0    0.0       1.0     0.0  ...               0              0   \n",
      "2136     1.0    1.0       1.0     0.0  ...               0              0   \n",
      "3411     0.0    0.0       0.0     1.0  ...               0              0   \n",
      "641      1.0    0.0       0.0     0.0  ...               0              0   \n",
      "...      ...    ...       ...     ...  ...             ...            ...   \n",
      "2515     1.0    0.0       0.0     0.0  ...               0              0   \n",
      "1487     0.0    1.0       0.0     1.0  ...               0              0   \n",
      "1543     0.0    0.0       0.0     0.0  ...               0              0   \n",
      "1798     1.0    0.0       0.0     1.0  ...               1              0   \n",
      "1126     1.0    1.0       0.0     0.0  ...               0              0   \n",
      "\n",
      "      Quan_4_ruthless  Quan_4_plans  Quan_4_secrets  Quan_4_single  \\\n",
      "242                 0             0               0              0   \n",
      "3191                0             0               0              0   \n",
      "2136                0             0               0              0   \n",
      "3411                0             0               0              0   \n",
      "641                 0             0               0              0   \n",
      "...               ...           ...             ...            ...   \n",
      "2515                0             0               0              0   \n",
      "1487                0             0               0              0   \n",
      "1543                0             0               0              0   \n",
      "1798                0             0               0              0   \n",
      "1126                0             0               0              0   \n",
      "\n",
      "      Quan_4_yet  Quan_4_company  Quan_4_just  Quan_4_uncover  \n",
      "242            0               0            0               0  \n",
      "3191           0               0            0               0  \n",
      "2136           0               0            0               0  \n",
      "3411           0               0            0               0  \n",
      "641            0               0            0               0  \n",
      "...          ...             ...          ...             ...  \n",
      "2515           0               0            0               0  \n",
      "1487           0               0            0               0  \n",
      "1543           0               0            0               0  \n",
      "1798           0               0            0               0  \n",
      "1126           0               0            1               0  \n",
      "\n",
      "[1687 rows x 137 columns]\n",
      "___________________\n",
      "Fitting 3 folds for each of 12000 candidates, totalling 36000 fits\n",
      "максимизация roc-auc\n",
      "accuracy =  0.8388625592417062 ; roc_auc =  0.6825792433537832 ; precision =  0.7916666666666666 ; recall =  0.3958333333333333\n"
     ]
    }
   ],
   "source": [
    "# №5 угадывание 5-ого квинтиля (лучших данных) по жанрам и второму рейтингу\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections\n",
    "np.random.seed(123)\n",
    "\n",
    "# Отключение некоторых лишних предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "        \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def popular_word_list(df, n):\n",
    "    top_words_count = n  # количество самых популярных слов для вывода\n",
    "\n",
    "    # Создаем массив из 5 списков для хранения самых популярных слов по каждому квинтилю\n",
    "    quintile_top_words = [[] for _ in range(5)]\n",
    "    quintile_top_words_list = [[] for _ in range(5)]\n",
    "\n",
    "    # Обходим каждую строку в таблице df_filtered\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        description = row['description'].lower()\n",
    "        quintile = row['quintile']\n",
    "\n",
    "        # Токенизируем описание фильма\n",
    "        tokens = word_tokenize(description)\n",
    "\n",
    "        # Исключаем незначащие слова\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in unmeaning_words]\n",
    "\n",
    "        # Обновляем частотное распределение слов\n",
    "        fdist = FreqDist(filtered_tokens)\n",
    "\n",
    "        # Получаем список самых популярных слов\n",
    "        top_words = [word for word, _ in fdist.most_common(top_words_count)]\n",
    "\n",
    "        # Добавляем список самых популярных слов в соответствующий список квинтиля\n",
    "        quintile_top_words[quintile - 1].extend(top_words)\n",
    "\n",
    "    for i in range (0, 5):\n",
    "        # Создаем словарь с подсчетом частоты встречаемости слов\n",
    "        word_counter = collections.Counter(quintile_top_words[i])\n",
    "\n",
    "        # Находим 50 самых часто встречающихся слов\n",
    "        top_words = word_counter.most_common(top_words_count)\n",
    "        quintile_top_words_list[i] = top_words\n",
    "\n",
    "    # Создаем новый массив со списками слов без чисел\n",
    "    words_list = [[pair[0] for pair in sublist] for sublist in quintile_top_words_list]\n",
    "\n",
    "    merged_list = []\n",
    "    for sublist in words_list:\n",
    "        merged_list.extend(sublist)\n",
    "\n",
    "    unique_words = []\n",
    "    for word in merged_list:\n",
    "        if merged_list.count(word) == 1:\n",
    "            unique_words.append(word)\n",
    "            \n",
    "    filtered_list = [[word for word in sublist if word in unique_words] for sublist in words_list]\n",
    "    return filtered_list\n",
    "\n",
    "df = pd.read_csv('result_films.csv')\n",
    "\n",
    "with open('unmeaning_words.txt', 'r') as file:\n",
    "    unmeaning_words = file.read().splitlines()\n",
    "\n",
    "# Создаем список уникальных жанров\n",
    "genres = set()\n",
    "for genre_list in df['genre']:\n",
    "    genres.update(genre_list.split(', '))\n",
    "\n",
    "# Обновляем значения столбцов жанров\n",
    "for index, row in df.iterrows():\n",
    "    genre_list = row['genre'].split(', ')\n",
    "    for genre in genre_list:\n",
    "        df.at[index, genre] = 1\n",
    "# Извлекаем год выпуска фильма и сохраняем его в отдельный столбец \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# Удаляем скобки и \"(I)\" из столбца \"release_year\"\n",
    "df['release_year'] = df['release_year'].str.replace(r'\\(I\\)', '')\n",
    "\n",
    "# Преобразуем столбец \"release_year\" в числовой формат\n",
    "df['release_year'] = df['release_year'].astype(int)    \n",
    "    \n",
    "df[\"imdb_rate\"] = df[\"imdb_rate\"].str.replace(',', '.').astype(float)\n",
    "\n",
    "df_filtered = df[df['votes'] >= 100000]\n",
    "# Разделение на квинтили по столбцу 'imdb_rate'\n",
    "df_filtered['quintile'] = pd.qcut(df_filtered['imdb_rate'], q=5, labels=False)\n",
    "\n",
    "# Convert 'quintile' column into binary columns\n",
    "df_dummies = pd.get_dummies(df_filtered['quintile'], prefix='quintile')\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "df_filtered = pd.concat([df_filtered, df_dummies], axis=1)\n",
    "\n",
    "# Drop the original 'quintile' column\n",
    "#df_filtered.drop('quintile', axis=1, inplace=True)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "df_filtered = df_filtered.drop({'name', 'global_rate', 'votes', 'duration', 'genre','imdb_rate', 'quintile_0',\n",
    "                                'quintile_1',  'quintile_2',  'quintile_3'}, axis=1)\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "features = df_filtered.drop(['quintile_4'], axis=1) \n",
    "target = df_filtered['quintile_4']\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#ищу самые популярные слова по кванттилям в тренировочной выборке\n",
    "filtered_list = popular_word_list(X_train, 100)\n",
    "\n",
    "# Создание столбцов с бинарными значениями\n",
    "for i, sublist in enumerate(filtered_list):\n",
    "    for word in sublist:\n",
    "        column_name = f'Quan_{i}_{word}'\n",
    "        X_train[column_name] = df['description'].apply(lambda x: 1 if word in x else 0)\n",
    "        X_test[column_name] = df['description'].apply(lambda x: 1 if word in x else 0)\n",
    "\n",
    "\n",
    "\n",
    "# Drop the original 'quintile' column\n",
    "X_train.drop('quintile', axis=1, inplace=True)\n",
    "X_test.drop('quintile', axis=1, inplace=True)\n",
    "X_train.drop('description', axis=1, inplace=True)\n",
    "X_test.drop('description', axis=1, inplace=True)\n",
    "\n",
    "numeric_data = X_train.select_dtypes([np.number])\n",
    "\n",
    "numeric_data_mean = numeric_data.mean() \n",
    "numeric_features = numeric_data.columns\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "\n",
    "#нормирование данных\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)  \n",
    "print(X_train)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "print('___________________')\n",
    "## подбор Solver'a\n",
    "## идеи с сайта https://www.kaggle.com/code/funxexcel/p2-logistic-regression-hyperparameter-tuning\n",
    "\n",
    "logModel = LogisticRegression()\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-5, 5, 40),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : np.logspace(1, 5, 15)\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1,scoring=\"roc_auc\" )\n",
    "best_clf = clf.fit(X_train_scaled,y_train)\n",
    "best_clf.best_estimator_\n",
    "\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('максимизация roc-auc')\n",
    "print('accuracy = ', accuracy, '; roc_auc = ',  roc_auc,'; precision = ', precision,'; recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc019048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
